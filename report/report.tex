\documentclass[12pt,a4paper]{article}

% Packages for better formatting
\usepackage[utf8]{inputenc}
\usepackage[title]{appendix}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{parskip} % Removes indents and adds space between paragraphs
\usepackage[colorlinks=false, allcolors=blue]{hyperref} % Makes the DOI a clickable link
\usepackage{svg}
\usepackage{placeins}
\usepackage{multirow}

\usepackage[
    % backend=biber,
    style=numeric,
    maxbibnames=99,    % Show all authors
    sorting=none       % Order by appearance
]{biblatex}
\addbibresource{references.bib}

\title{Unsupervised Human Activity Recognition on the UCI-HAR Dataset}
\author{Eduard-Valentin Dumitrescul}
\date{\today}


\begin{document}

\maketitle
\tableofcontents


\clearpage
\section{Introduction}
\label{sec:introduction}

\textbf{Human Activity Recognition (HAR)} plays a significant role in modern health monitoring, fitness tracking, and elderly care systems. This technology utilizes inertial sensors---specifically accelerometers and gyroscopes---embedded in mobile devices to gather high-frequency data about a user's movement. By training machine learning models on this data, it is possible to classify physical movement into distinct categories.

Traditional learning models used for HAR, such as \textbf{Support Vector Machines (SVM)}, are supervised. These models require large, manually labeled datasets to function effectively. However, labeling data is a labor-intensive process that is not always feasible for real-world applications. 

This project explores \textbf{unsupervised learning}, specifically \textbf{Self-Organizing Maps (SOM)} and \textbf{Mean-Shift Clustering}. The primary goal is to determine if these algorithms can discover the underlying structure of human movement without prior knowledge of activity labels. A supervised SVM is implemented alongside these models to serve as a performance benchmark.


\subsection{UCI-HAR Dataset Overview}
\label{sec:dataset}
The \textbf{UCI-HAR} dataset \cite{human_activity_recognition_using_smartphones_240} 
is a standard benchmark for Human Activity Recognition tasks.
The data was collected from 30 subjects  performing 6 activities (walking, walking upstairs, walking downstairs, sitting, standing, laying) 

During the experiments, the subjects wore a Samsung Galaxy S II smartphone tied to their waist. Using the device's embedded accelerometer and gyroscope, movement and orientation data was collected at a rate of 50Hz
The captured information was later manually labeled using video recording of the subjects.

The resulting database consists of 7352 train examples and 2947 test examples were created. Each example consists of  a 561-feature vector derived from the collected data.

\section{Methodology}
\label{sec:methodology}
The UCI-HAR dataset presents an opportunity to employ two distinct learning paradigms: supervised and unsupervised. 
The primary objective is to compare these two types of algorithms in order to discover if the models that do not 
have access to class labels are able to discover the underlying structure of the data.

\subsection {Models}
A total of 3 models (1 supervised, 2 unsupervised) have been trained and evaluated on the UCI-HAR dataset.
\label{sec:models}
\subsubsection{Support Vector Machine}

For the benchmark model, a \textbf{Support Vector Machine} is used. It is a classic machine learning algorithm known for its efficiency and high-performance on tabular data. In the context of UCI-HAR, the SVM is effective in finding
hyperplanes delimiting the activity classes.

\subsubsection{Self-Organizing Maps (SOM)}
The first unsuperised model is a \textbf{Self-Organizing Map (SOM)}. This is a type of artificial neural network that performs dimensionality-reduction by mapping high-dimensional data onto a low-dimensional space (often 2D), while preserving the topological properties of the input data.
Because similar items are clustered together on the grid, the overall structure can be easily visualized.

\subsubsection{Mean-Shift Clustering}
The second unsupervised model is a \textbf{Mean-Shift Clustering} algorithm, which clusters data by iteratively shifting items towards high-density areas.Unlike other algorithms, Mean-Shift Clusterin determines the number of clusters based on the data itself, allowing us to see if the data naturally groups together.

\subsection{Model Input Strategies}
While selecting the feature sets, it is important to consider that clustering algorithms, specifically Self-Organizing Maps (SOM) and Mean-Shift Clustering, suffer from the \textbf{curse of dimensionality}. A high number of dimensions causes the data point to be sparse, which makes distance-based metrics (like Euclidean distance) unreliable. To mitigate this, the models will be trained on multiple feature sets: 

\begin{itemize}
    \item The original 561-feature vector. This serves as a baseline for the models
    \item Manually selected features. A reduced set of features based on physical reasoning.
    \item Principal Component Analysis (PCA): A reduced set of uncorrelated components, which preserves most of the information.
\end{itemize}


\subsection{Unsupervised Model Evaluation}

\subsubsection{Internal Validation (Clustering Specific Metrics)}
\label{subsec:internal_metrics}

In order to measure how well the clustering algorithms have separated the data points into distinct groups, we will use
the \textbf{Silhouette Score}.

\begin{equation}
s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}
\end{equation}

\text{Where:}
\begin{itemize}
    \item $s(i)$: Silhouette coefficient for a single sample $i$.
    \item $a(i)$: Mean intra-cluster distance (average distance to all other points in the same cluster).
    \item $b(i)$: Mean nearest-cluster distance (average distance to all points in the closest cluster of which $i$ is not a member).
    \item $S = \frac{1}{n} \sum_{i=1}^{n} s(i)$: Global silhouette score for $n$ samples.
\end{itemize}

Specific to the \textbf{Self-Organizing Map} algorithm, we are also computing:
\begin{itemize}
    \item \textbf{Quantization Error (QE)}: The average Euclidean distance between each input sample and its BMU.
    \item \textbf{Topographic Error (TE)}: The proportion of input samples for each the 1st BMU and the 2nd BMU are not 
    neighbors
\end{itemize}

% Discuss the Silhouette Score (separation/cohesion) and Distance Metrics (centroid proximity).
% For SOM, include Quantization Error and Topographic Error.

\subsubsection{External Validation (Projected Label Evaluation)}
After the models have been trained, the resulting clusters will be labeled using majority voting based on the real labels.
The aim is to compute metrics similar to the SVM (e.g accuracy, f1-score) and directly compare the supervised model 
with the unsupervised ones.


\label{subsec:external_metrics}


\section{Feature Extraction and Engineering}
\label{sec:features}

\subsection{Feature Set 1: Original 561-feature vectors}
The baseline feature set consists of the full 561-dimensional vectors provided by the UCI-HAR dataset. They were calculated from the 
3-axial linear acceleration and angular velocity signals. The creators applied various filters and transformations, including Fast Fourier Transform to produce frequency domain variabled\cite{human_activity_recognition_using_smartphones_240}. This set represents the most comprehensive data available, but poses the risk of the curse of dimensionality.

\FloatBarrier
\subsection{Feature Set 2: Manually Selected Domain Features}
A hand-picked set of 15 features was selected based on the physical state differences between the 6 activities.
\begin{itemize} 
    \item \textbf{Static Orientation (Laying vs. Others):} To distinguish the "Laying" state (horizontal) from vertical states (Sitting, Standing, Walking), we selected the mean gravity acceleration components across all three axes: \texttt{tGravityAcc-mean()-X}, \texttt{Y}, and \texttt{Z}.

    \item \textbf{Dynamic vs. Static States (Moving vs. Non-Moving):} To separate active movements (Walking, Stairs) from rest (Sitting, Standing, Laying), we included the Signal Magnitude Area (\texttt{tBodyAcc-sma()}) and the standard deviation of body acceleration magnitude (\texttt{tBodyAccMag-std()}).

    \item \textbf{Rhythmic Motion and Gait (Walking vs. Stairs):} Distinguishing walking from stair navigation requires capturing the cadence and intensity of movement. We have chosen the following features in an attempt to capture that information.
        \begin{itemize}
            \item Gyroscope Jerk standard deviation: \texttt{tBodyGyroJerk-std()-X}, \texttt{Y}, and \texttt{Z}.
            \item Mean angular velocity: \texttt{tBodyGyro-mean()-X}.
            \item Frequency-domain body acceleration: \texttt{fBodyAcc-mean()-X}.
            \item Frequency-domain magnitude mean frequency: \texttt{fBodyAccMag-meanFreq()}.
        \end{itemize}



    \item \textbf{Postural Stability (Standing vs. Sitting):} These two states are predicted to be difficult to separate. To capture the subtle movements present while standing compared to the more rigid seated posture, we included:
        \begin{itemize}
            \item Gyroscope standard deviation: \texttt{tBodyGyro-std()-X}, \texttt{Y}, and \texttt{Z}.
            \item Angular velocity jerk magnitude: \texttt{tBodyGyroJerkMag-std()}.
        \end{itemize}
\end{itemize}

\FloatBarrier
\subsection{Feature Set 3: Principal Component Analysis (PCA)}

Principal Component Analysis is used to transform the original 561-dimensional vectors into lower-dimensional ones, while preserving the majority of the information. This algorithm calculates new uncorrelated features that will be fed to the models.

\begin{figure}
    \centering
    \includesvg[width=0.8\textwidth]{../fig/pca_explained_variance.svg}
    \caption{PCA Explained Variance Ratio}
\end{figure}

Various numbers of components have been extracted using PCA:

\begin{itemize}
    \item \textbf{10 components} preserve 80\% of the original dataset's variance.
    \item \textbf{34 compoentns} preserve 90\% of the original dataset's variance.
    \item \textbf{67 components} preserve 95\% of the original dataset's variance.
\end{itemize}

\section{Random Baseline}
Given how the accuracy is computed for the unsupervised models, a totally random algorithm is expected to achieve 
16.66\% accuracy, given 6 labels. Such a model would not produce significant differences in the per-class precision, 
recall or f1-score.

\section {Unsupervised Model: Support Vector Machine}

\subsection{Training on Full Feature Set}

Grid search was used to find the best parameter configuration for the SVM. Results can be seen in the table below. The model achieves \textbf{96.54\%} accuracy on the test subset.



\begin{table}[htbp]
    \centering
    \begin{tabular}{l | c c c c}
    \hline
    & \multicolumn{4}{c}{\textbf{Regularization Parameter ($C$)}} \\
    \textbf{Gamma ($\gamma$)} & \textbf{0.1} & \textbf{1} & \textbf{10} & \textbf{100} \\
    \hline
    \texttt{'scale'} & 91.28\% & 95.05\% & 96.20\% & \textbf{96.54\%} \\
    \texttt{0.01}    & 92.30\% & 94.98\% & 96.20\% & \textbf{96.54\%} \\
    \texttt{0.001}   & 80.96\% & 92.77\% & 95.39\% & 96.17\% \\
    \hline
    \end{tabular}
    \caption{Grid Search Results for SVM on Full Feature Set (561 features). Results represent Test Accuracy using an RBF kernel.}
    \label{tab:grid_search_full}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{@{}lcccc@{}}
    \toprule
    \textbf{Activity} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \midrule
    Walking            & 0.96               & 0.99            & 0.97              & 496              \\
    Walking Upstairs   & 0.95               & 0.96            & 0.96              & 471              \\
    Walking Downstairs & 0.99               & 0.95            & 0.97              & 420              \\
    Sitting            & 0.98               & 0.90            & 0.94              & 491              \\
    Standing           & 0.92               & 0.98            & 0.95              & 532              \\
    Laying             & 1.00               & 1.00            & 1.00              & 537              \\ \midrule
    \textbf{Accuracy}  &                    &                 & \textbf{0.97}     & \textbf{2947}    \\
    Macro Avg          & 0.97               & 0.96            & 0.96              & 2947             \\
    Weighted Avg       & 0.97               & 0.97            & 0.97              & 2947             \\ \bottomrule
    \end{tabular}
    \caption{Detailed Classification Report for the Optimized SVM (Full Feature Set)}
    \label{tab:svm_classification_report}
\end{table}

\subsection{Training on Manually Selected Feature Set}

To evaluate the efficiency of the domain-specific features, the SVM was retrained on the 15-dimensional subset. As shown in the results below, the model remains highly effective despite a significant reduction in input dimensionality.

\begin{table}[htbp]
    \centering
    \begin{tabular}{l | c c c c}
    \hline
    & \multicolumn{4}{c}{\textbf{Regularization Parameter ($C$)}} \\
    \textbf{Gamma ($\gamma$)} & \textbf{0.1} & \textbf{1} & \textbf{10} & \textbf{100} \\
    \hline
    \texttt{'scale'} & 89.48\% & \textbf{90.16\%} & 88.97\% & 89.01\% \\
    \texttt{0.01}    & 85.31\% & 89.89\%          & 89.92\% & 89.38\% \\
    \texttt{0.001}   & 51.95\% & 84.97\%          & 89.55\% & 89.82\% \\
    \hline
    \end{tabular}
    \caption{Grid Search Results for SVM on Manual Feature Set (15 domain-specific features). Results represent Test Accuracy using an RBF kernel.}
    \label{tab:grid_search_manual}
\end{table}


\begin{table}[htbp]
    \centering
    \begin{tabular}{@{}lcccc@{}}
    \toprule
    \textbf{Activity} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \midrule
    Walking            & 0.91               & 0.96            & 0.93              & 496              \\
    Walking Upstairs   & 0.87               & 0.89            & 0.88              & 471              \\
    Walking Downstairs & 0.94               & 0.85            & 0.89              & 420              \\
    Sitting            & 0.89               & 0.77            & 0.83              & 491              \\
    Standing           & 0.82               & 0.91            & 0.86              & 532              \\
    Laying             & 1.00               & 1.00            & 1.00              & 537              \\ \midrule
    \textbf{Accuracy}  &                    &                 & \textbf{0.90}     & \textbf{2947}    \\ \bottomrule
    \end{tabular}
    \caption{Classification Report: Manual Feature Set.}
    \label{tab:svm_manual_report}
\end{table}

\FloatBarrier
\subsection{Training on PCA Feature Set (80\% Variance)}

To evaluate the impact of automated dimensionality reduction, the SVM was trained on the first 10 principal components, which capture 80\% of the dataset's variance. This configuration tests the model's robustness when restricted to the most significant statistical features.

The grid search results in Table \ref{tab:grid_search_pca80} indicate that the model achieves a peak accuracy of \textbf{88.26\%} at $C=100$ and $\gamma=scale$. While lower than the manual feature set (90.16\%), it represents a high degree of information density for only 10 dimensions.

\begin{table}[htbp]
    \centering
    \begin{tabular}{l | c c c c}
    \hline
    & \multicolumn{4}{c}{\textbf{Regularization Parameter ($C$)}} \\
    \textbf{Gamma ($\gamma$)} & \textbf{0.1} & \textbf{1} & \textbf{10} & \textbf{100} \\
    \hline
    \texttt{'scale'} & 86.60\% & 87.72\% & 88.12\% & \textbf{88.26\%} \\
    \texttt{0.01}    & 85.71\% & 87.72\% & 87.75\% & 88.12\% \\
    \texttt{0.001}   & 78.08\% & 86.02\% & 87.72\% & 88.02\% \\
    \hline
    \end{tabular}
    \caption{Grid Search Results: PCA Feature Set (10 components, 80\% Variance).}
    \label{tab:grid_search_pca80}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{@{}lcccc@{}}
    \toprule
    \textbf{Activity} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \midrule
    Walking            & 0.87               & 0.98            & 0.92              & 496              \\
    Walking Upstairs   & 0.90               & 0.90            & 0.90              & 471              \\
    Walking Downstairs & 0.93               & 0.80            & 0.86              & 420              \\
    Sitting            & 0.81               & 0.72            & 0.76              & 491              \\
    Standing           & 0.77               & 0.87            & 0.82              & 532              \\
    Laying             & 1.00               & 0.98            & 0.99              & 537              \\ \midrule
    \textbf{Accuracy}  &                    &                 & \textbf{0.88}     & \textbf{2947}    \\ \bottomrule
    \end{tabular}
    \caption{Classification Report: PCA Feature Set (80\% Variance).}
    \label{tab:svm_report_pca80}
\end{table}

\subsection{Interpretation}
The SVM achieves great accuracy on the full feature dataset and good accuracy on the manually selected features and PCA feature set. The main difficulty encounted by the model is the distunguishing between \textit{Sitting} and \textit{Standing}, as expected (\ref{fig:svm_full_cm}, \ref{fig:svm_manual_cm} \ref{fig:svm_pca80_cm}). \textit{Laying} is the easiest to classify, achieving almost perfect metrics for all three features sets. Static and dynamic classes are easily distinguished between one another.

\section{Unsupervised Model 1: Self-Organizing Maps}
\label{sec:som}
Self-Organizing Maps (SOM) were employed to projects the high-dimensional data (561, 15, repectively 10 dimensions) to a 
2-dimensional grid.

Model Parameters:
\begin{itemize}
    \item \textbf{Grid size}: Determines the resolution of the final map and the number of clusters that represent the input space.
    \item  \textbf{Learning rate}: Controls how aggresive the weihts are updated between iterations.  
    \item  \textbf{Sigma}: Defines the neighborhood radius. A larger value prioritizes global ordering, while a lower one focuses on local fine-tuning
\end{itemize}
The SOM algorithm works by initializing a weight vector for each neuron in the grid. Each iteration consists of three steps:
\begin{enumerate}
    \item \textbf{Competition}: For each input sample, the neuron with the smallest Euclidean distance is calculated (\textit{Best Matching Unit}).
    \item \textbf{Cooperation}: The BMU identifies the neurons in its neighborhood.
    \item \textbf{Adaptation}: The weight vectors of the BMU and its neighbors are updated.
\end{enumerate}

\subsection{Training}

Grid Search was emplyed on each feature set with the following parameters:
\begin{itemize}
    \item \textbf{Grid Size(4x4, 6x6, 8x8, 10x10, 20x20)}
    \item \textbf{Sigma Ratio(0.2, 0.4, 0.6)}: This is relative to the grid size (e.g. sigma ratio 0.2 for grid size 10x10 is sigma 2)
    \item \textbf{Learning Rate(0.5)}: For fast learning
    \item \textbf{Number of Iterations(5000)}
\end{itemize}

\textbf{Quantization Error (QE)} and \textbf{Topographic Error (TE)} are calculated for each configuration. For ensuring the input data is correctly mapped to the grid, only the results having a TE lower than 0.1 are considered.
Then, the QE is the deciding factor, while also prioritizing small grid sizes.

\begin{table}[h]
\centering
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \textbf{Grid Size} & \textbf{Sigma 0.2} & \textbf{Sigma 0.4} & \textbf{Sigma 0.6} \\ \midrule
            4 $\times$ 4   & 4.277 / 0.511 & 4.375 / 0.196 & 4.557 / 0.084 \\
            6 $\times$ 6   & 3.879 / 0.384 & 4.276 / 0.119 & 4.461 / 0.048 \\
            8 $\times$ 8   & 3.789 / 0.266 & 4.206 / 0.093 & 4.383 / 0.067 \\
            10 $\times$ 10 & 3.690 / 0.245 & 4.158 / 0.090 & 4.400 / 0.159 \\
            20 $\times$ 20 & 3.559 / 0.143 & 4.141 / 0.069 & 4.309 / 0.055 \\ \bottomrule
        \multicolumn{4}{l}{\small \textit{Note: Cells show Quantization Error (QE) / Topographic Error (TE)}}
    \end{tabular}
    \caption{SOM Grid Search Results: Full (561) Feature Set}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{@{}lccc@{}}
    \toprule
    \textbf{Grid Size} & \textbf{Sigma 0.2} & \textbf{Sigma 0.4} & \textbf{Sigma 0.6} \\ \midrule
    4 $\times$ 4   & 1.510 / 0.190 & 1.613 / 0.034 & 1.775 / 0.007 \\
    6 $\times$ 6   & 1.274 / 0.279 & 1.488 / 0.030 & 1.694 / 0.035 \\
    8 $\times$ 8   & 1.155 / 0.231 & 1.455 / 0.040 & 1.700 / 0.028 \\
    10 $\times$ 10 & 1.067 / 0.101 & 1.422 / 0.048 & 1.614 / 0.049 \\
    20 $\times$ 20 & 0.977 / 0.072 & 1.381 / 0.068 & 1.579 / 0.037 \\ \bottomrule
    \multicolumn{4}{l}{\small \textit{Note: Cells show Quantization Error (QE) / Topographic Error (TE)}}
    \end{tabular}
    \caption{SOM Grid Search Results: Manual (15) Feature Set}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{@{}lccc@{}}
    \toprule
    \textbf{Grid Size} & \textbf{Sigma 0.2} & \textbf{Sigma 0.4} & \textbf{Sigma 0.6} \\ \midrule
    4 $\times$ 4   & 2.253 / 0.167 & 2.453 / 0.078 & 2.755 / 0.150 \\
    6 $\times$ 6   & 1.897 / 0.205 & 2.357 / 0.062 & 2.578 / 0.065 \\
    8 $\times$ 8   & 1.794 / 0.108 & 2.261 / 0.078 & 2.488 / 0.051 \\
    10 $\times$ 10 & 1.726 / 0.190 & 2.211 / 0.055 & 2.463 / 0.059 \\
    20 $\times$ 20 & 1.621 / 0.088 & 2.144 / 0.036 & 2.401 / 0.037 \\ \bottomrule
    \multicolumn{4}{l}{\small \textit{Note: Cells show Quantization Error (QE) / Topographic Error (TE)}}
    \end{tabular}
    \caption{SOM Grid Search Results: PCA (80\%) Feature Set}
\end{table}

\FloatBarrier
As observed from the three tables above, a good configuration for the SOM requires a balance between topographic preservation and quantization accuracy. Specifically, configurations with a \textit{Sigma Ratio} of 0.2 often resulted in a Topographic Error exceeding the 0.1 threshold, indicating a neighborhood radius too small to maintain the global structure of the map. 

By prioriziting compact grids and the selection criteria (filtering for $TE < 0.1$ and selecting the minimum $QE$):
\begin{itemize}
    \item \textbf{Full (561):} The \textbf{$6 \times 6$} grid with \textbf{0.6 Sigma Ratio} ($QE=4.461, TE=0.048$).
    \item \textbf{Manual (15):} The \textbf{$4 \times 4$} grid with \textbf{0.4 Sigma Ratio} ($QE=1.488, TE=0.035$).
    \item \textbf{PCA (80\%):} The \textbf{$6 \times 6$} grid with \textbf{0.4 Sigma Ratio} ($QE=2.357, TE=0.062$).
\end{itemize}

The table below shows the results after running the previous 3 configuration on both 4 by 4 and 6 by 6 grids. Three new metrics were added:
\begin{itemize}
    \item \textbf{Accuracy}: Each cell was labeled it using a majority vote algorithm based on the labels for the samples belonging to it. Then, using the testing subset, the accuracy was calculated.
    \item \textbf{Average Purity}: Each cell has an associated purity based on what percentage of the samples beloging to it are labeled like the majority.
    \item \textbf{Pure Neurons}: The percentage of cells having the purity greater than 90\%.
\end{itemize}

\begin{table}[h]
    \centering
    
    \begin{tabular}{@{}llccccc@{}}
    \toprule
    \textbf{Feature Set} & \textbf{Grid} & \textbf{ACC} & \textbf{QE / TE} & \textbf{Avg. Purity} & \textbf{Pure Neurons} \\ \midrule
    \multirow{2}{*}{PCA (80\%)} & 6 $\times$ 6 & \textbf{0.7475} & 2.448 / 0.051 & \textbf{0.8042} & 30.56\% \\
                                & 4 $\times$ 4 & 0.6098 & 2.805 / 0.150 & 0.7714 & 31.25\% \\ \midrule
    \multirow{2}{*}{Full (561)} & 6 $\times$ 6 & 0.6583 & 4.675 / 0.154 & 0.8038 & \textbf{47.22\%} \\
                                & 4 $\times$ 4 & 0.6298 & 4.906 / 0.279 & 0.7762 & 43.75\% \\ \midrule
    \multirow{2}{*}{Manual (15)}& 6 $\times$ 6 & 0.6922 & \textbf{1.661 / 0.059} & 0.7484 & 27.78\% \\
                                & 4 $\times$ 4 & 0.6230 & 1.834 / \textbf{0.041} & 0.7187 & 25.00\% \\ \bottomrule
    \end{tabular}
    \label{tab:som_final_results}
    \caption{Comparison of SOM Performance across Feature Sets and Grid Sizes}
\end{table}

From these results it can be concluded that, while being far from the results of a supervised SVM, the SOM is able to successfully cluster and distinguish activity labels, without having access to labels during training. The best accuracy and average purity is achieved when training on the PCA feature set with a 6 by 6 grid. However, the manual set obtains the smallest Quantization Error and Topographic Error, while having a larger input dimension (15 compared to 10 of the PCA feature set).

\begin{figure}
    \centering
    \includesvg[width = 0.8\textwidth]{../fig/som_pca_labeled_grid.svg}
    \caption{Labeled grid for the 6 by 6 PCA model}
\end{figure}

\subsection{Notes}
It is important to acknowledge that a grid with more cells will naturally achieve better results, due to how they are labeled. For this reason, The 4 by 4 manual feature set model might perform better than the 6 by 6 PCA model. Due to the discrepancy between the unsupervised nature of the models and the supervised nature of the task, it is hard to selected an objectively best model.

\section{Unsupervised Model 2: Mean-Shift Clustering}
\label{sec:meanshift}

The Mean-Shift Clustering is a mode-searching algorithm that groups the data points in an unpredetermined number of 
clusters. It works by iteratively moving the data points towards the high-density areas. The 4 steps involved are:
\begin{enumerate}
    \item \textbf{Initialization}: All data points are considered potential cluster centers.
    \item \textbf{Density Computation}: Based on the \textbf{bandwidth}, a window surrounding each data point is calculated and 
    the mean is calculated for the points inside this window.
    \item \textbf{Movement}: The points are shiften towards the previously calculated mean.
    \item \textbf{Repetition}: Steps 2 and 3 are repeated until the shift is smaller than a predetermined threshold.
\end{enumerate}

\subsection{Training}
Grid Search was employed on each feature set with the following parameters:
\begin{itemize}
    \item \textbf{bandwidth}: 2, 2.2, 2.4, 2.6, 2.8, 3.0, 3.2, 3.4, 3.6, 3.8, 4.0
    \item \textbf{Number of Iterations}: 1000
\end{itemize}

The \textbf{Silhouette Score} and the \textbf{Number of Clusters} are used to select the best performing confiuration.
Ideally, a silhouette score greater than 0.5 and a number of clusters similar to the actual number of labels is the goal.

\begin{table}[h]
    \centering
    \begin{tabular}{@{}ccc@{}}
    \toprule
    \textbf{Bandwidth} & \textbf{Silhouette Score} & \textbf{Cluster Count} \\ \midrule
    2.0 & 0.0860 & 70 \\
    2.2 & 0.1005 & 47 \\
    2.4 & 0.1230 & 39 \\
    2.6 & 0.1539 & 22 \\
    2.8 & 0.1877 & 13 \\
    3.0 & 0.2071 & 13 \\
    3.2 & 0.2303 & 10 \\
    3.4 & 0.2759 & 8  \\
    3.6 & 0.2792 & 5  \\
    3.8 & 0.2805 & 5  \\
    4.0 & 0.2742 & 4  \\ \bottomrule
    \end{tabular}
    \caption{Mean Shift Grid Search Results: PCA Feature Set}
\end{table}



\begin{table}[h]
    \centering
    \begin{tabular}{@{}ccc@{}}
    \toprule
    \textbf{Bandwidth} & \textbf{Silhouette Score} & \textbf{Cluster Count} \\ \midrule
    2.0 & 0.3068 & 17 \\
    2.2 & 0.3467 & 9  \\
    2.4 & 0.3708 & 8  \\
    2.6 & 0.3737 & 7  \\
    2.8 & 0.3612 & 5  \\
    3.0 & 0.4308 & 4  \\
    3.2 & 0.4308 & 4  \\
    3.4 & 0.4879 & 3  \\
    3.6 & 0.4879 & 2  \\
    3.8 & 0.4879 & 2  \\
    4.0 & 0.4879 & 2  \\ \bottomrule
    \end{tabular}
    \caption{Mean Shift Grid Search Results: Manual Feature Set}
\end{table}

\FloatBarrier
As observed from the tables above, Mean-Shift Clustering is not able to successfully cluster the data points when using 
the 10-dimensional PCA components. The bandwidth that will be used for this feature set is 3.4, as it achieves one of 
the highest Silhouette Scores and 8 clusters (compared to 6 labels).

However, when trained on the manually selected features, the model achieves significantly better results. At a bandwidth 
equal to 2.6, Mean-Shift Clustering has a Silhouette Score of 0.37 and 7 clusters. Higher scores are achieved with different 
bandwidths, but they group the data into too few clusters for our task.

With the selected set of bandwidths, the model was not able to train using the full feature set, highlighting its
limitations when using high-dimensional input.

\subsection{Results}

Using a similar labeling approach to the previoud unsupervised model, the two configuration achieve the following 
results:

\begin{table}[h]
    \centering
    \begin{tabular}{@{}lcc@{}}
    \toprule
    \textbf{Metric / Class} & \textbf{PCA Feature Set} & \textbf{Manual Feature Set} \\ \midrule
    \textbf{Accuracy}       & 0.56                     & 0.52                        \\ \midrule
    \textit{F1-Score per Class:} & & \\
    WALKING                 & 0.54                     & 0.52                        \\
    WALKING\_UPSTAIRS       & 0.00                     & 0.00                        \\
    WALKING\_DOWNSTAIRS     & 0.45                     & 0.05                        \\
    SITTING                 & 0.00                     & 0.00                        \\
    STANDING                & 0.68                     & 0.68                        \\
    LAYING                  & 1.00                     & 0.97                        \\ \midrule
    Macro Avg F1            & 0.45                     & 0.37                        \\
    Weighted Avg F1         & 0.46                     & 0.39                        \\ \bottomrule
    \end{tabular}
    \caption{Classification Comparison: PCA vs. Manual Feature Sets}
\end{table}

\FloatBarrier
The results are well over random, but very modest for both configuration. The model is only able to distinguish
Laying, Dynamic labels (Walking, Walking Upstairs and Wlaking Downstairs) and Vertical Static (Standing and Sitting).



\FloatBarrier
\section{Comparative Analysis and Discussion}
\label{sec:discussion}
This report showed that unsupervised learning algorithms can effectively be employed for supervised tasks. While not 
able the achieve the same results as a classic Support Vector Machine, both Self-Organizing Maps and Mean-Shift 
Clustering successfully grouped the feature space into distinct clusters.

Both unsupervised models performed poorly when trained with the full-feature set, a limitation common for clustering 
algorithms. Both the 10-dimensional PCA-based features set and the 15-dimensional manually 
selected feature set can be regarded as similarly performant.

A direct comparison between the Self-Organizing Map and the Mean-Shift Clustering algorithms cannot be made, as they 
have different goals. If we look at the common metrics, the label prediction accuracy, it may seem the Self-Organizing 
Map outperforms the Mean-Shift Clustering. However, the larger number of cells used for prediction by the SOM 
automatically increases the accuracy. Configurations with a similar number of cells/clusters achieve similar accuracies.

\pagebreak
\printbibliography

\newpage
\begin{appendix}
\section{Supplementary Figures}
\label{appendix:supplementary_figures}

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/svm_full_cm.svg}
    \caption{Full Confusion Matrix: 561-Feature SVM.}
    \label{fig:svm_full_cm}
\end{figure}



\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/svm_manual_cm.svg}
    \caption{Confusion Matrix: 15-Feature Manual SVM.}
    \label{fig:svm_manual_cm}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/svm_manual_feature_importance.svg}
    \caption{Permutation Importance for Manual Feature Set.}
    \label{fig:svm_manual_importance}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/svm_pca80_cm.svg}
    \caption{Confusion Matrix: 10-Feature PCA SVM.}
    \label{fig:svm_pca80_cm}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/msc_pca_cm.svg}
    \caption{Confusion Matrix: 10-Feature PCA Mean-Shift Clustering.}
    \label{fig:msc_pca_cm}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.8\textwidth]{../fig/msc_manual_cm.svg}
    \caption{Confusion Matrix: 15-Feature Manual Mean-Shift Clustering.}
    \label{fig:msc_manual_cm}
\end{figure}



\end{appendix}
\end{document}